{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gmlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5sF8jVpamBh"
      },
      "source": [
        "import torch\n",
        "import einops\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O7HgAaXcR1w"
      },
      "source": [
        "class SpatialGatingUnit(nn.Module):\n",
        "    def __init__(self, seq_len, d_ffn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(d_ffn)\n",
        "        self.spatial_proj = nn.Conv1d(seq_len, seq_len, kernel_size=1)\n",
        "        nn.init.constant_(self.spatial_proj.bias, 1.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        u, v = x.chunk(2, dim=-1)\n",
        "        v = self.norm(v)\n",
        "        v = self.spatial_proj(v)\n",
        "        return u * v"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbZvAKH5eS09"
      },
      "source": [
        "class gMLPBlock(nn.Module):\n",
        "    def __init__(self, seq_len, d_model, d_ffn):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, 2 * d_ffn), # channel proj\n",
        "            nn.GELU(),\n",
        "            SpatialGatingUnit(seq_len, d_ffn), # contains spatial proj\n",
        "            nn.Linear(d_ffn, d_model) # channel proj\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXez7K0MfyK2"
      },
      "source": [
        "class gMLP(nn.Module):\n",
        "    def __init__(self, seq_len=256, d_model=256, d_ffn=512, n_layers=6):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[gMLPBlock(seq_len, d_model, d_ffn) for _ in range(n_layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.blocks(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuXMfw5Ei0W-"
      },
      "source": [
        "class gMLPVisionModel(nn.Module):\n",
        "    def __init__(self, in_channels=3, image_size=256, patch_size=16, d_model=256, d_ffn=512, n_layers=6, n_classes=1000):\n",
        "        super().__init__()\n",
        "        assert image_size % patch_size == 0, \"image size must be divisible by patch size!!\"\n",
        "        n_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_embedding = nn.Conv2d(in_channels, d_model, kernel_size=patch_size, stride=patch_size)\n",
        "        self.gmlp = gMLP(n_patches, d_model, d_ffn, n_layers)\n",
        "        self.fc_out = nn.Linear(d_model, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        x = einops.rearrange(x, \"b c h w -> b (h w) c\")\n",
        "        x = self.gmlp(x)\n",
        "        x = x.mean(1)\n",
        "        out = self.fc_out(x)\n",
        "        return out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BPUJelUgGA9"
      },
      "source": [
        "class gMLPLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size=10000, seq_len=256, d_model=256, d_ffn=512, n_layers=6, padding_idx=None):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=padding_idx)\n",
        "        self.gmlp = gMLP(seq_len, d_model, d_ffn, n_layers)\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.gmlp(x)\n",
        "        out = self.fc_out(x)\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiEsw6JiRlGx",
        "outputId": "e053df87-0920-4725-fa83-8fec4443c7f0"
      },
      "source": [
        "# hyperparameters for vision and language models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_epochs = 2\n",
        "seq_len = 128\n",
        "img_size = 256\n",
        "batch_size = 64\n",
        "n_classes = 10\n",
        "lr = 3e-4\n",
        "T = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((img_size, img_size)),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1kcQ0sfjNs_"
      },
      "source": [
        "# vision model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds9yEGdYiS3R",
        "outputId": "8f5979fd-8fcf-4894-d04f-a73dd019dbb1"
      },
      "source": [
        "train_data_vm = datasets.CIFAR10(\"data/\", train=True, download=True, transform=T)\n",
        "val_data_vm = datasets.CIFAR10(\"data/\", train=False, download=True, transform=T)\n",
        "train_loader_vm = DataLoader(train_data_vm, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader_vm = DataLoader(val_data_vm, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "x, y = next(iter(train_loader_vm))\n",
        "print(len(train_data_vm), x.shape, y.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "50000 torch.Size([64, 3, 256, 256]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcwhTE2wiSz3",
        "outputId": "011796e3-d687-4067-d0b0-00fe81788466"
      },
      "source": [
        "gmlp_vm = gMLPVisionModel(n_classes=n_classes).to(device)\n",
        "inp = torch.randn(1, 3, img_size, img_size).to(device)\n",
        "out = gmlp_vm(inp)\n",
        "print(out.shape)\n",
        "del inp, out"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu6RNYVOiSxg"
      },
      "source": [
        "optimizer_vm = torch.optim.Adam(gmlp_vm.parameters(), lr=lr)\n",
        "loss_fn_vm = nn.CrossEntropyLoss()\n",
        "def get_accuracy(preds, y):\n",
        "    preds = preds.argmax(dim=1, keepdim=True)\n",
        "    correct = preds.squeeze(1).eq(y)\n",
        "    acc = correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
        "    return acc"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODz_ZhBjiSvT"
      },
      "source": [
        "def loop_vm(net, loader, is_train):\n",
        "    net.train(is_train)\n",
        "    losses = []\n",
        "    accs = []\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            preds = net(x)\n",
        "            loss = loss_fn_vm(preds, y)\n",
        "            acc = get_accuracy(preds, y)\n",
        "            losses.append(loss.item())\n",
        "            accs.append(acc.item())\n",
        "        if is_train:\n",
        "            optimizer_vm.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_vm.step()\n",
        "        pbar.set_description(f'epoch={epoch}, train={int(is_train)}, loss={np.mean(losses):.4f}, acc={np.mean(accs):.4f}')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMzHCbQJiStX",
        "outputId": "dc8adc85-36b9-4d10-c3e9-e5a298eaa0e8"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    loop_vm(gmlp_vm, train_loader_vm, True)\n",
        "    loop_vm(gmlp_vm, val_loader_vm, False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=0, train=1, loss=1.5804, acc=0.4246: 100%|██████████| 782/782 [04:10<00:00,  3.12it/s]\n",
            "epoch=0, train=0, loss=1.2501, acc=0.5511: 100%|██████████| 157/157 [00:25<00:00,  6.08it/s]\n",
            "epoch=1, train=1, loss=1.1410, acc=0.5915: 100%|██████████| 782/782 [04:10<00:00,  3.12it/s]\n",
            "epoch=1, train=0, loss=1.0838, acc=0.6127: 100%|██████████| 157/157 [00:25<00:00,  6.06it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfdpMjXjjyAJ"
      },
      "source": [
        "@torch.no_grad()\n",
        "def recognize_img(net, img):\n",
        "    net.eval()\n",
        "    img = Image.open(img).convert(\"RGB\")\n",
        "    img = T(img).to(device)\n",
        "    pred = net(img.unsqueeze(0))\n",
        "    pred = pred.argmax(dim=1)\n",
        "    return train_data_vm.classes[pred.item()]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXbIw4q7kQoo",
        "outputId": "6b52f465-7f36-451f-92a4-2492b3ad9628"
      },
      "source": [
        "# get 'dog.jpg' from https://github.com/zer0sh0t/artificial_intelligence/blob/master/vision_models/vision_transformer/cifar_10_dataset/test_images/dog.jpg\n",
        "out = recognize_img(gmlp_vm, 'dog.jpg')\n",
        "print(out)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmeteOIGjLZy"
      },
      "source": [
        "# language model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSoPvVpI55vo"
      },
      "source": [
        "class GetDataset(Dataset):\n",
        "    def __init__(self, text, seq_len):\n",
        "        self.text = text\n",
        "        chars = sorted(list(set(text)))\n",
        "        self.vocab_size = len(chars)        \n",
        "        self.stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "        self.itos = {i: ch for i, ch in enumerate(chars)}\n",
        "        self.seq_len = seq_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.text) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        chunk = self.text[index: index + self.seq_len + 1]\n",
        "        idxs = [self.stoi[s] for s in chunk]\n",
        "        x = torch.LongTensor(idxs[:-1])\n",
        "        y = torch.LongTensor(idxs[1:])\n",
        "        return x, y"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1c1SlXg55sE",
        "outputId": "fed95f0c-0ac4-486a-bffd-0e2f9a637820"
      },
      "source": [
        "# get 'input.txt' from https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt\n",
        "text = open('input.txt', 'r').read()\n",
        "data = GetDataset(text, seq_len)\n",
        "padding_idx = data.vocab_size\n",
        "data.vocab_size += 1 # adding padding idx to vocab\n",
        "loader_lm = DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "x, y = next(iter(loader_lm))\n",
        "print(len(data), padding_idx, data.vocab_size, x.shape, y.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1115266 65 66 torch.Size([64, 128]) torch.Size([64, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDSpxnJ-55nk",
        "outputId": "30b4e9fb-1358-4d82-fdb6-cac344ed0c21"
      },
      "source": [
        "x, y = data[42]\n",
        "print(x, x.shape)\n",
        "print(y, y.shape)\n",
        "x = ''.join([data.itos[i.item()] for i in x])\n",
        "y = ''.join([data.itos[i.item()] for i in y])\n",
        "print(x, y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1, 57, 54, 43, 39, 49,  8,\n",
            "         0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,  6,  1, 57, 54, 43, 39,\n",
            "        49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,\n",
            "         0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,  1, 56, 43, 57, 53, 50,\n",
            "        60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58, 53,  1, 42, 47, 43,  1,\n",
            "        58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47, 57, 46, 12,  0,  0, 13,\n",
            "        50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,  8,  1, 56, 43, 57, 53,\n",
            "        50, 60]) torch.Size([128])\n",
            "tensor([56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1, 57, 54, 43, 39, 49,  8,  0,\n",
            "         0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,  6,  1, 57, 54, 43, 39, 49,\n",
            "         8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0,\n",
            "        37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,  1, 56, 43, 57, 53, 50, 60,\n",
            "        43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58, 53,  1, 42, 47, 43,  1, 58,\n",
            "        46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47, 57, 46, 12,  0,  0, 13, 50,\n",
            "        50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,  8,  1, 56, 43, 57, 53, 50,\n",
            "        60, 43]) torch.Size([128])\n",
            "er, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolv r, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpJsfRqv55iv",
        "outputId": "57148a8d-b930-439d-fc31-5bb868bd5ae7"
      },
      "source": [
        "gmlp_lm = gMLPLanguageModel(vocab_size=data.vocab_size, seq_len=seq_len, padding_idx=padding_idx).to(device)\n",
        "inp = torch.randint(0, data.vocab_size, (1, seq_len)).to(device)\n",
        "out = gmlp_lm(inp)\n",
        "print(inp.shape, out.shape)\n",
        "del inp, out\n",
        "optimizer_lm = torch.optim.Adam(gmlp_lm.parameters(), lr=lr)\n",
        "loss_fn_lm = nn.CrossEntropyLoss(ignore_index=padding_idx)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128]) torch.Size([1, 128, 66])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I0v80fmSZZY"
      },
      "source": [
        "def loop_lm(net, loader):\n",
        "    net.train()\n",
        "    losses = []\n",
        "    ppls = []\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "    \n",
        "        preds = net(x)\n",
        "        preds = preds.view(-1, preds.shape[-1])\n",
        "        y = y.view(-1)\n",
        "        loss = loss_fn_lm(preds, y)\n",
        "        ppl = loss.exp()\n",
        "        losses.append(loss.item())\n",
        "        ppls.append(ppl.item())\n",
        "    \n",
        "        optimizer_lm.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
        "        optimizer_lm.step()\n",
        "        pbar.set_description(f'epoch={epoch}, loss={np.mean(losses):.4f}, ppl={np.mean(ppls):.4f}')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "mm9OJRZ3SZXH",
        "outputId": "a3676087-47bd-47a4-e14b-cdba17ddc566"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    loop_lm(gmlp_lm, loader_lm)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=0, loss=0.0818, ppl=1.3070:  32%|███▏      | 5599/17427 [14:22<30:20,  6.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-39264004e6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloop_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmlp_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_lm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-b487e02f2372>\u001b[0m in \u001b[0;36mloop_lm\u001b[0;34m(net, loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch={epoch}, loss={np.mean(losses):.4f}, ppl={np.mean(ppls):.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_description_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 )\n\u001b[1;32m    504\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXR8b67WSYjq"
      },
      "source": [
        "@torch.no_grad()\n",
        "def generate_txt(net, prime, steps, temperature=1.0, sample=False):\n",
        "    net.eval()\n",
        "    tokens = torch.LongTensor([data.stoi[s] for s in prime]).unsqueeze(0)\n",
        "    b, t = tokens.shape\n",
        "    if t < seq_len:\n",
        "        padding = torch.full((b, seq_len - t), padding_idx)\n",
        "        x = torch.cat((padding, tokens), dim=1).to(device)\n",
        "    else:\n",
        "        x = tokens.to(device)\n",
        "\n",
        "    for k in range(steps):\n",
        "        x_cond = x if x.shape[1] <= seq_len else x[:, -seq_len:]\n",
        "        out = net(x_cond)\n",
        "        out = out[:, -1, :] / temperature\n",
        "        probs = out.softmax(-1)\n",
        "        if sample:\n",
        "            idx = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, idx = torch.topk(probs, k=1, dim=-1)\n",
        "        x = torch.cat((x, idx), dim=1)\n",
        "    out = ''.join([data.itos[i.item()] for i in x[0] if i != padding_idx])\n",
        "    return out"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpLRf8ySSYgT",
        "outputId": "9bb5c52d-9c2f-4ee7-834b-0edba9cd3c5c"
      },
      "source": [
        "prime = \"what are you doing \"\n",
        "steps = 200\n",
        "out = generate_txt(gmlp_lm, prime, steps)\n",
        "print(out)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what are you doing then tone of the speacen hereforences hour here the speacen here the speace here the see here the see here the dies he she fair; the first the she first the see here the she first the see her she with\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}