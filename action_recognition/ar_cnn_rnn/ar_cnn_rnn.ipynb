{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ar_cnn_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "osJqEbjP98lR"
      },
      "source": [
        "!wget -q https://git.io/JGc31 -O ucf101_top5.tar.gz # downloading only a sample of ucf101 dataset\n",
        "!tar xf ucf101_top5.tar.gz"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35ld8rjV9mwn"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from IPython.core.display import Video\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cl2CzA69jtl",
        "outputId": "7f9070c3-90d9-47ec-9959-2fe73b692104"
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "print(len(train_df), len(test_df))\n",
        "print(train_df.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "594 224\n",
            "                  video_name          tag\n",
            "0  v_CricketShot_g08_c01.avi  CricketShot\n",
            "1  v_CricketShot_g08_c02.avi  CricketShot\n",
            "2  v_CricketShot_g08_c03.avi  CricketShot\n",
            "3  v_CricketShot_g08_c04.avi  CricketShot\n",
            "4  v_CricketShot_g08_c05.avi  CricketShot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSU9t4uoFs5-"
      },
      "source": [
        "f = glob.glob('train/*.*')[42]\n",
        "Video(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ja5P-C8Funi"
      },
      "source": [
        "f = glob.glob('test/*.*')[42]\n",
        "Video(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBVAb4SmC4gG",
        "outputId": "565f75dc-48c5-4781-b4b0-b11d17bfc181"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_epochs = 30\n",
        "img_size = 299\n",
        "batch_size = 64\n",
        "max_seq_len = 20\n",
        "n_features = 2048 # output shape of inception_v3, if the final fc layer is removed\n",
        "hidden1 = 16\n",
        "hidden2 = 8\n",
        "drop_prob = 0.4\n",
        "lr = 1e-3\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh0i1DRN_bsI",
        "outputId": "39cef356-d447-43b9-be6d-319e6717b452"
      },
      "source": [
        "inception = models.inception_v3(pretrained=True, aux_logits=False)\n",
        "inception.fc = nn.Identity()\n",
        "inception = inception.to(device)\n",
        "inp = torch.randn(1, 3, 299, 299).to(device)\n",
        "out = inception(inp)\n",
        "print(out.shape)\n",
        "del inp, out"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2048])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z34YsGsAljr",
        "outputId": "f9254995-2c54-499d-9037-034e5888c761"
      },
      "source": [
        "labels = train_df['tag'].values.tolist()\n",
        "i2l = list(np.unique(labels))\n",
        "l2i = {}\n",
        "for i, l in enumerate(i2l):\n",
        "    l2i[l] = i\n",
        "print(i2l, l2i)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CricketShot', 'PlayingCello', 'Punch', 'ShavingBeard', 'TennisSwing'] {'CricketShot': 0, 'PlayingCello': 1, 'Punch': 2, 'ShavingBeard': 3, 'TennisSwing': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EntW1h6J-a6i"
      },
      "source": [
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "def load_video(path, max_frames, resize):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frames.append(frame)\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return frames # (n_frames, h, w, 3)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmxP58uZAlpy"
      },
      "source": [
        "@torch.no_grad()\n",
        "def prepare_all_videos(net, df, root_dir, max_seq_len, resize):\n",
        "    net.eval()\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "    frame_features = []\n",
        "    frame_lenghts = []\n",
        "    labels = df[\"tag\"].values\n",
        "    labels = [l2i[l] for l in labels]\n",
        "\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        frames = load_video(os.path.join(root_dir, path), max_seq_len, resize) # (n_frames, h, w, 3)\n",
        "        curr_frame_featutes = np.zeros((max_seq_len, n_features))\n",
        "        vid_len = len(frames)\n",
        "        curr_len = min(max_seq_len, vid_len)\n",
        "\n",
        "        for i, frame in enumerate(frames):\n",
        "            frame = transforms.ToTensor()(frame).unsqueeze(0).to(device)\n",
        "            curr_frame_featutes[i] = net(frame)[0].detach().cpu().numpy()\n",
        "            if i + 1 == curr_len:\n",
        "                break\n",
        "\n",
        "        frame_features.append(curr_frame_featutes)\n",
        "        frame_lenghts.append(curr_len)\n",
        "    return torch.FloatTensor(frame_features), torch.IntTensor(frame_lenghts), torch.LongTensor(labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-DkdeTsKHUF"
      },
      "source": [
        "train_x, train_y, train_z = prepare_all_videos(inception, train_df, 'train', max_seq_len, (img_size, img_size))\n",
        "test_x, test_y, test_z = prepare_all_videos(inception, test_df, 'test', max_seq_len, (img_size, img_size))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GviIsZvVzpbk",
        "outputId": "449e0907-beac-42c9-a787-8da57bdbfc3b"
      },
      "source": [
        "train_data = TensorDataset(train_x, train_y, train_z)\n",
        "test_data = TensorDataset(test_x, test_y, test_z)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=2, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=2, shuffle=True, pin_memory=True)\n",
        "x, y, z = next(iter(train_loader))\n",
        "print(len(train_data), x.shape, y.shape, z.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "594 torch.Size([64, 20, 2048]) torch.Size([64]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyh_l9FaKbZm"
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden1, hidden2, output_size, drop_prob):\n",
        "        super().__init__()\n",
        "        self.gru1 = nn.GRU(input_size, hidden1, batch_first=True)\n",
        "        self.gru2 = nn.GRU(hidden1, hidden2, batch_first=True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc1 = nn.Linear(hidden2, hidden2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden2, output_size)\n",
        "\n",
        "    def forward(self, frames, frame_lengths):\n",
        "        packed_frames = nn.utils.rnn.pack_padded_sequence(frames, frame_lengths, batch_first=True)\n",
        "        packed_x, _ = self.gru1(packed_frames)\n",
        "        packed_x, h = self.gru2(packed_x)\n",
        "        # x, x_len = nn.utils.rnn.pad_packed_sequence(packed_x)\n",
        "        h = self.dropout(h.squeeze(0)) # (1, bs, d) -> (bs, d)\n",
        "        h = self.relu(self.fc1(h))\n",
        "        return self.fc2(h)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zYejpiH9vJC",
        "outputId": "80f0573e-c4c8-4338-93fd-551fda48eb42"
      },
      "source": [
        "seq_model = SequentialModel(n_features, hidden1, hidden2, len(i2l), drop_prob).to(device)\n",
        "inp = torch.randn(2, 5, 2048).to(device)\n",
        "inp_len = torch.tensor([4, 3])\n",
        "out = seq_model(inp, inp_len)\n",
        "print(out.shape)\n",
        "del inp, inp_len, out"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm199U8l_Qzd"
      },
      "source": [
        "optimizer = torch.optim.Adam(seq_model.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "def get_accuracy(preds, y):\n",
        "    preds = preds.argmax(dim=1, keepdim=True)\n",
        "    correct = preds.squeeze(1).eq(y)\n",
        "    acc = correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
        "    return acc"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXzAcs17_A9g"
      },
      "source": [
        "def loop(net, loader, is_train):\n",
        "    net.train(is_train)\n",
        "    losses = []\n",
        "    accs = []\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    for frames, frame_lengths, labels in pbar:\n",
        "        frames = frames.to(device)\n",
        "        frame_lengths = frame_lengths.cpu() # this needs to be on cpu\n",
        "        labels = labels.to(device)\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            preds = net(frames, frame_lengths)\n",
        "            loss = loss_fn(preds, labels)\n",
        "            acc = get_accuracy(preds, labels)\n",
        "            losses.append(loss.item())\n",
        "            accs.append(acc.item())\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        pbar.set_description(f'epoch={epoch}, train={int(is_train)}, loss={np.mean(losses):.4f}, acc={np.mean(accs):.4f}')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwy0FkmMxvqg",
        "outputId": "b77f8658-eb3a-485d-b610-323c49a60d8c"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    loop(seq_model, train_loader, True)\n",
        "    loop(seq_model, test_loader, False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=0, train=1, loss=1.6001, acc=0.2316: 100%|██████████| 10/10 [00:00<00:00, 31.96it/s]\n",
            "epoch=0, train=0, loss=1.5896, acc=0.2617: 100%|██████████| 4/4 [00:00<00:00, 22.78it/s]\n",
            "epoch=1, train=1, loss=1.5556, acc=0.3090: 100%|██████████| 10/10 [00:00<00:00, 33.65it/s]\n",
            "epoch=1, train=0, loss=1.5577, acc=0.3828: 100%|██████████| 4/4 [00:00<00:00, 23.70it/s]\n",
            "epoch=2, train=1, loss=1.5070, acc=0.3981: 100%|██████████| 10/10 [00:00<00:00, 34.87it/s]\n",
            "epoch=2, train=0, loss=1.5219, acc=0.3633: 100%|██████████| 4/4 [00:00<00:00, 22.35it/s]\n",
            "epoch=3, train=1, loss=1.4563, acc=0.4780: 100%|██████████| 10/10 [00:00<00:00, 33.80it/s]\n",
            "epoch=3, train=0, loss=1.4910, acc=0.4062: 100%|██████████| 4/4 [00:00<00:00, 23.20it/s]\n",
            "epoch=4, train=1, loss=1.3967, acc=0.5290: 100%|██████████| 10/10 [00:00<00:00, 34.95it/s]\n",
            "epoch=4, train=0, loss=1.4429, acc=0.4375: 100%|██████████| 4/4 [00:00<00:00, 22.63it/s]\n",
            "epoch=5, train=1, loss=1.3420, acc=0.5938: 100%|██████████| 10/10 [00:00<00:00, 34.04it/s]\n",
            "epoch=5, train=0, loss=1.4175, acc=0.4727: 100%|██████████| 4/4 [00:00<00:00, 23.20it/s]\n",
            "epoch=6, train=1, loss=1.2959, acc=0.6047: 100%|██████████| 10/10 [00:00<00:00, 34.27it/s]\n",
            "epoch=6, train=0, loss=1.3786, acc=0.5352: 100%|██████████| 4/4 [00:00<00:00, 21.97it/s]\n",
            "epoch=7, train=1, loss=1.2355, acc=0.6481: 100%|██████████| 10/10 [00:00<00:00, 34.42it/s]\n",
            "epoch=7, train=0, loss=1.3413, acc=0.5312: 100%|██████████| 4/4 [00:00<00:00, 22.66it/s]\n",
            "epoch=8, train=1, loss=1.1854, acc=0.6939: 100%|██████████| 10/10 [00:00<00:00, 35.36it/s]\n",
            "epoch=8, train=0, loss=1.3003, acc=0.5273: 100%|██████████| 4/4 [00:00<00:00, 22.93it/s]\n",
            "epoch=9, train=1, loss=1.1128, acc=0.7104: 100%|██████████| 10/10 [00:00<00:00, 34.08it/s]\n",
            "epoch=9, train=0, loss=1.2693, acc=0.5898: 100%|██████████| 4/4 [00:00<00:00, 21.70it/s]\n",
            "epoch=10, train=1, loss=1.0541, acc=0.7370: 100%|██████████| 10/10 [00:00<00:00, 34.78it/s]\n",
            "epoch=10, train=0, loss=1.2185, acc=0.5625: 100%|██████████| 4/4 [00:00<00:00, 21.77it/s]\n",
            "epoch=11, train=1, loss=0.9872, acc=0.7715: 100%|██████████| 10/10 [00:00<00:00, 34.78it/s]\n",
            "epoch=11, train=0, loss=1.1722, acc=0.5859: 100%|██████████| 4/4 [00:00<00:00, 22.03it/s]\n",
            "epoch=12, train=1, loss=0.9345, acc=0.7873: 100%|██████████| 10/10 [00:00<00:00, 34.89it/s]\n",
            "epoch=12, train=0, loss=1.1518, acc=0.5898: 100%|██████████| 4/4 [00:00<00:00, 23.37it/s]\n",
            "epoch=13, train=1, loss=0.8981, acc=0.7981: 100%|██████████| 10/10 [00:00<00:00, 34.90it/s]\n",
            "epoch=13, train=0, loss=1.0949, acc=0.6055: 100%|██████████| 4/4 [00:00<00:00, 23.14it/s]\n",
            "epoch=14, train=1, loss=0.8205, acc=0.8365: 100%|██████████| 10/10 [00:00<00:00, 33.58it/s]\n",
            "epoch=14, train=0, loss=1.0609, acc=0.6914: 100%|██████████| 4/4 [00:00<00:00, 23.67it/s]\n",
            "epoch=15, train=1, loss=0.7749, acc=0.8536: 100%|██████████| 10/10 [00:00<00:00, 33.44it/s]\n",
            "epoch=15, train=0, loss=1.0027, acc=0.6758: 100%|██████████| 4/4 [00:00<00:00, 22.28it/s]\n",
            "epoch=16, train=1, loss=0.7235, acc=0.8632: 100%|██████████| 10/10 [00:00<00:00, 33.83it/s]\n",
            "epoch=16, train=0, loss=0.9574, acc=0.7148: 100%|██████████| 4/4 [00:00<00:00, 23.90it/s]\n",
            "epoch=17, train=1, loss=0.6892, acc=0.8780: 100%|██████████| 10/10 [00:00<00:00, 34.29it/s]\n",
            "epoch=17, train=0, loss=0.9636, acc=0.7266: 100%|██████████| 4/4 [00:00<00:00, 22.58it/s]\n",
            "epoch=18, train=1, loss=0.6586, acc=0.8780: 100%|██████████| 10/10 [00:00<00:00, 33.91it/s]\n",
            "epoch=18, train=0, loss=0.9013, acc=0.7031: 100%|██████████| 4/4 [00:00<00:00, 22.29it/s]\n",
            "epoch=19, train=1, loss=0.6052, acc=0.9021: 100%|██████████| 10/10 [00:00<00:00, 34.50it/s]\n",
            "epoch=19, train=0, loss=0.8564, acc=0.7617: 100%|██████████| 4/4 [00:00<00:00, 20.85it/s]\n",
            "epoch=20, train=1, loss=0.5605, acc=0.8936: 100%|██████████| 10/10 [00:00<00:00, 31.82it/s]\n",
            "epoch=20, train=0, loss=0.9191, acc=0.7383: 100%|██████████| 4/4 [00:00<00:00, 22.36it/s]\n",
            "epoch=21, train=1, loss=0.5668, acc=0.8780: 100%|██████████| 10/10 [00:00<00:00, 35.88it/s]\n",
            "epoch=21, train=0, loss=0.8066, acc=0.7461: 100%|██████████| 4/4 [00:00<00:00, 22.97it/s]\n",
            "epoch=22, train=1, loss=0.5458, acc=0.8988: 100%|██████████| 10/10 [00:00<00:00, 32.23it/s]\n",
            "epoch=22, train=0, loss=0.7849, acc=0.7617: 100%|██████████| 4/4 [00:00<00:00, 22.66it/s]\n",
            "epoch=23, train=1, loss=0.4849, acc=0.9203: 100%|██████████| 10/10 [00:00<00:00, 34.54it/s]\n",
            "epoch=23, train=0, loss=0.7301, acc=0.7656: 100%|██████████| 4/4 [00:00<00:00, 22.45it/s]\n",
            "epoch=24, train=1, loss=0.4584, acc=0.9092: 100%|██████████| 10/10 [00:00<00:00, 34.56it/s]\n",
            "epoch=24, train=0, loss=0.7113, acc=0.7891: 100%|██████████| 4/4 [00:00<00:00, 22.66it/s]\n",
            "epoch=25, train=1, loss=0.4356, acc=0.9398: 100%|██████████| 10/10 [00:00<00:00, 34.93it/s]\n",
            "epoch=25, train=0, loss=0.7286, acc=0.7656: 100%|██████████| 4/4 [00:00<00:00, 23.45it/s]\n",
            "epoch=26, train=1, loss=0.3866, acc=0.9484: 100%|██████████| 10/10 [00:00<00:00, 34.16it/s]\n",
            "epoch=26, train=0, loss=0.6748, acc=0.7930: 100%|██████████| 4/4 [00:00<00:00, 22.75it/s]\n",
            "epoch=27, train=1, loss=0.3842, acc=0.9398: 100%|██████████| 10/10 [00:00<00:00, 34.77it/s]\n",
            "epoch=27, train=0, loss=0.7090, acc=0.7539: 100%|██████████| 4/4 [00:00<00:00, 23.55it/s]\n",
            "epoch=28, train=1, loss=0.3795, acc=0.9281: 100%|██████████| 10/10 [00:00<00:00, 33.48it/s]\n",
            "epoch=28, train=0, loss=0.6465, acc=0.8047: 100%|██████████| 4/4 [00:00<00:00, 22.48it/s]\n",
            "epoch=29, train=1, loss=0.3395, acc=0.9413: 100%|██████████| 10/10 [00:00<00:00, 35.01it/s]\n",
            "epoch=29, train=0, loss=0.7204, acc=0.7773: 100%|██████████| 4/4 [00:00<00:00, 22.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQHhsVX8Aasc"
      },
      "source": [
        "@torch.no_grad()\n",
        "def predict(net, seq_model, path, max_seq_len, resize):\n",
        "    net.eval()\n",
        "    seq_model.eval()\n",
        "    frames = load_video(path, max_seq_len, resize) # (n_frames, h, w, 3)\n",
        "    frame_features = np.zeros((max_seq_len, n_features))\n",
        "    vid_len = len(frames)\n",
        "    frame_len = min(max_seq_len, vid_len)\n",
        "    for i, frame in enumerate(frames):\n",
        "        frame = transforms.ToTensor()(frame).unsqueeze(0).to(device)\n",
        "        frame_features[i] = net(frame)[0].detach().cpu().numpy()\n",
        "        if i + 1 == frame_len:\n",
        "            break\n",
        "\n",
        "    frame_features = torch.FloatTensor([frame_features]).to(device)\n",
        "    frame_len = torch.IntTensor([frame_len]).cpu()\n",
        "    preds = seq_model(frame_features, frame_len)\n",
        "    probs = preds.softmax(-1).squeeze(0)\n",
        "    probs, idxs = probs.sort(descending=True)\n",
        "    for prob, idx in zip(probs, idxs):\n",
        "        print(f'P({i2l[idx]}) = {prob:.4f}')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/test/v_ShavingBeard_g03_c04.avi": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "oULZT_9vGq7V",
        "outputId": "0539a137-eb13-4c84-f557-0a0d2dd85501"
      },
      "source": [
        "idx = 42\n",
        "vid_path = f\"test/{test_df['video_name'][idx]}\"\n",
        "label = test_df['tag'][idx]\n",
        "predict(inception, seq_model, vid_path, max_seq_len, (img_size, img_size))\n",
        "print(f'label: {label}')\n",
        "Video(f)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(CricketShot) = 0.7285\n",
            "P(Punch) = 0.2045\n",
            "P(PlayingCello) = 0.0560\n",
            "P(TennisSwing) = 0.0065\n",
            "P(ShavingBeard) = 0.0045\n",
            "label: CricketShot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video src=\"test/v_ShavingBeard_g03_c04.avi\" controls>\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/test/v_ShavingBeard_g03_c04.avi": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "Fnmlo9I3X3jE",
        "outputId": "46acd5ab-7737-422e-cbdf-37f7189e4b46"
      },
      "source": [
        "idx = 69\n",
        "vid_path = f\"test/{test_df['video_name'][idx]}\"\n",
        "label = test_df['tag'][idx]\n",
        "predict(inception, seq_model, vid_path, max_seq_len, (img_size, img_size))\n",
        "print(f'label: {label}')\n",
        "Video(f)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(PlayingCello) = 0.9240\n",
            "P(CricketShot) = 0.0508\n",
            "P(TennisSwing) = 0.0168\n",
            "P(Punch) = 0.0044\n",
            "P(ShavingBeard) = 0.0040\n",
            "label: PlayingCello\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video src=\"test/v_ShavingBeard_g03_c04.avi\" controls>\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}