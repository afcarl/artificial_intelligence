{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "default.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x67aiDLnmAFr"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import random_split, DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1lu9D8nmAA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe45acea-7d70-4abb-f656-b85469983582"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_epochs = 1\n",
        "img_size = 224\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "lr = 3e-4\n",
        "T = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((img_size, img_size)),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEqeu1oKxQ2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249f3aa7-9b31-48c8-d743-c5d2d0a331d4"
      },
      "source": [
        "data = datasets.CIFAR10(\"data/\", train=True, download=True, transform=T)\n",
        "test_data = datasets.CIFAR10(\"data/\", train=False, download=True, transform=T)\n",
        "\n",
        "val_len = int(0.3 * len(data))\n",
        "train_data, val_data = random_split(data, [len(data) - val_len, val_len])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "print(len(train_data), len(val_data), len(test_data), x.shape, y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "35000 15000 10000 torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyIAD4OGxQz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c77927-b513-4290-f3f4-431a530bfebd"
      },
      "source": [
        "net = models.resnet18(pretrained=False)\n",
        "net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
        "net.to(device)\n",
        "\n",
        "inp = torch.randn(1, 3, 224, 224).to(device)\n",
        "out = net(inp)\n",
        "print(out.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmhUIywQlggJ"
      },
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "def get_accuracy(preds, y):\n",
        "    preds = preds.argmax(dim=1, keepdim=True)\n",
        "    correct = preds.squeeze(1).eq(y)\n",
        "    acc = correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
        "    return acc"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr8kkFfIkiES"
      },
      "source": [
        "def loop(net, loader, is_train, epoch=None):\n",
        "    net.train(is_train)\n",
        "    losses = []\n",
        "    accs = []\n",
        "    if is_train:\n",
        "        split = 'train'\n",
        "    else:\n",
        "        split = ' val '\n",
        "\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            preds = net(x)\n",
        "            loss = loss_fn(preds, y)\n",
        "            acc = get_accuracy(preds, y)\n",
        "            losses.append(loss.item())\n",
        "            accs.append(acc.item())\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        if epoch != None:\n",
        "            pbar.set_description(f'{split}: epoch={epoch}, loss={np.mean(losses):.4f}, acc={np.mean(accs):.4f}')\n",
        "        else:\n",
        "            pbar.set_description(f'loss={np.mean(losses):.4f}, acc={np.mean(accs):.4f}')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yswvI8SIxraI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939e3f8e-9d6e-4f09-c5ce-ce767053ae60"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    loop(net, train_loader, True, epoch)\n",
        "    loop(net, val_loader, False, epoch)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: epoch=0, loss=1.3293, acc=0.5191: 100%|██████████| 547/547 [03:15<00:00,  2.80it/s]\n",
            " val : epoch=0, loss=1.2758, acc=0.5424: 100%|██████████| 235/235 [00:32<00:00,  7.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd73ztTZzdh1",
        "outputId": "c781e6a3-6634-4424-fd0e-8db2033c044c"
      },
      "source": [
        "loop(net, test_loader, False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss=1.2643, acc=0.5444: 100%|██████████| 157/157 [00:22<00:00,  7.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}