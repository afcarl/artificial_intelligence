{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tpu_single_core.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZH_R8P4z7Ne"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf-OER4MxWp6"
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import random_split, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOhCqnpMxWmU",
        "outputId": "9ed0f554-35d7-4ee7-aae0-e27ffc914c84"
      },
      "source": [
        "device = xm.xla_device() # to use a single core\n",
        "n_epochs = 1\n",
        "img_size = 224\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "lr = 3e-4\n",
        "T = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((img_size, img_size)),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp9GaLRqxWi6",
        "outputId": "cfd2fb8e-f8d5-4bd2-de6e-808667bb4dad"
      },
      "source": [
        "data = datasets.CIFAR10(\"data/\", train=True, download=True, transform=T)\n",
        "test_data = datasets.CIFAR10(\"data/\", train=False, download=True, transform=T)\n",
        "\n",
        "val_len = int(0.3 * len(data))\n",
        "train_data, val_data = random_split(data, [len(data) - val_len, val_len])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "print(len(train_data), len(val_data), len(test_data), x.shape, y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "35000 15000 10000 torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20dziZ2vxWfv",
        "outputId": "600d14f6-c42c-4c08-9e9b-dc8f0d7be57c"
      },
      "source": [
        "net = models.resnet18(pretrained=False)\n",
        "net.fc = nn.Linear(net.fc.in_features, num_classes)\n",
        "net.to(device)\n",
        "\n",
        "inp = torch.randn(1, 3, 224, 224).to(device)\n",
        "out = net(inp)\n",
        "print(out.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO8yYFYBxWcZ"
      },
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "def get_accuracy(preds, y):\n",
        "    preds = preds.argmax(1)\n",
        "    num_correct = (preds == y).sum().item()\n",
        "    acc = num_correct / y.shape[0]\n",
        "    return acc"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeVIo3w9xWZN"
      },
      "source": [
        "def loop(net, loader, is_train, epoch=None):\n",
        "    net.train(is_train)\n",
        "    losses = []\n",
        "    accs = []\n",
        "    if is_train:\n",
        "        split = 'train'\n",
        "    else:\n",
        "        split = ' val '\n",
        "\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            preds = net(x)\n",
        "            loss = loss_fn(preds, y)\n",
        "            acc = get_accuracy(preds, y)\n",
        "            losses.append(loss.item())\n",
        "            accs.append(acc)\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer, barrier=True) # tpu-specific code\n",
        "        \n",
        "        if epoch != None:\n",
        "            pbar.set_description(f'{split}: epoch={epoch}, loss={np.mean(losses):.4f}, acc={np.mean(accs):.4f}')\n",
        "        else:\n",
        "            pbar.set_description(f'loss={np.mean(losses):.4f}, acc={np.mean(accs):.4f}')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQYkUOeFxWWb",
        "outputId": "a48373fe-e668-487c-9e07-ea7a322457cd"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    loop(net, train_loader, True, epoch)\n",
        "    loop(net, val_loader, False, epoch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: epoch=0, loss=1.3215, acc=0.5198: 100%|██████████| 547/547 [05:18<00:00,  1.72it/s]\n",
            " val : epoch=0, loss=1.1623, acc=0.5922: 100%|██████████| 235/235 [02:11<00:00,  1.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYJQvDcaxWTm",
        "outputId": "3da2221e-a280-49bb-a4eb-de7fe4784e00"
      },
      "source": [
        "loop(net, test_loader, False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss=1.1700, acc=0.5891: 100%|██████████| 157/157 [01:24<00:00,  1.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}