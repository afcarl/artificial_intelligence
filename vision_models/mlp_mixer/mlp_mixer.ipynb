{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_mixer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZCHPABWLQgx",
        "outputId": "1ef4e3d3-6dff-4aec-d692-283bce10a1d8"
      },
      "source": [
        "!pip install einops"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2__ZGg07RYrd"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from einops.layers.torch import Rearrange\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItIFvceyuTmM"
      },
      "source": [
        "class MlpBlock(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, p=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p),\n",
        "            nn.Linear(hidden_dim, in_dim),\n",
        "            nn.Dropout(p)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As7xSlulxDHD"
      },
      "source": [
        "class MixerBlock(nn.Module):\n",
        "    def __init__(self, num_patches, chn_dim, tok_hid_dim, chn_hid_dim, p=0.):\n",
        "        super().__init__()\n",
        "        self.token_mixing = nn.Sequential(\n",
        "                                nn.LayerNorm(chn_dim),\n",
        "                                Rearrange('b t d -> b d t'),\n",
        "                                MlpBlock(num_patches, tok_hid_dim, p),\n",
        "                                Rearrange('b d t -> b t d')\n",
        "                            )\n",
        "        self.channel_mixing = nn.Sequential(\n",
        "                                nn.LayerNorm(chn_dim),\n",
        "                                MlpBlock(chn_dim, chn_hid_dim, p)\n",
        "                            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + self.token_mixing(x)\n",
        "        x = x + self.channel_mixing(x)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2wOve7S2U6U"
      },
      "source": [
        "class MlpMixer(nn.Module):\n",
        "    def __init__(self, in_channels, img_size, chn_dim, patch_size, num_blocks, tok_hid_dim, chn_hid_dim, num_classes, p=0.):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0, 'image size must be divisible by patch size!!'\n",
        "        num_patches = (img_size // patch_size) ** 2\n",
        "        self.patch_embedding = nn.Sequential(\n",
        "                                    nn.Conv2d(in_channels, chn_dim, kernel_size=patch_size, stride=patch_size),\n",
        "                                    Rearrange('b c h w -> b (h w) c')\n",
        "                                )\n",
        "        self.mixer_blocks = nn.ModuleList([MixerBlock(num_patches, chn_dim, tok_hid_dim, chn_dim, p) for _ in range(num_blocks)])\n",
        "        self.ln = nn.LayerNorm(chn_dim)\n",
        "        self.fc_out = nn.Linear(chn_dim, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        for mixer_block in self.mixer_blocks:\n",
        "            x = mixer_block(x)\n",
        "        x = self.ln(x)\n",
        "        x = x.mean(1)\n",
        "        return self.fc_out(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KNIAQXH6j8P",
        "outputId": "9ff86eb3-71df-49f5-b1a2-6cd790c23d04"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_epochs = 10\n",
        "in_channels = 3\n",
        "img_size = 224\n",
        "chn_dim = 512\n",
        "patch_size = 32\n",
        "num_blocks = 8\n",
        "tok_hid_dim = 256\n",
        "chn_hid_dim = 2048\n",
        "num_classes = 10\n",
        "p = 0.\n",
        "batch_size = 64\n",
        "lr = 3e-4\n",
        "T = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((img_size, img_size)),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkT9XIbX7fwV",
        "outputId": "3092208c-e7ac-49fe-fc62-c4986c09954f"
      },
      "source": [
        "train_data = datasets.CIFAR10(\"data/\", train=True, download=True, transform=T)\n",
        "val_data = datasets.CIFAR10(\"data/\", train=False, download=True, transform=T)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "x, y = next(iter(train_loader))\n",
        "print(len(train_data), x.shape, y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "50000 torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXOvn01F4rud",
        "outputId": "c458cf20-6807-46a5-cb8a-513dbb491330"
      },
      "source": [
        "net = MlpMixer(in_channels, img_size, chn_dim, patch_size, num_blocks, tok_hid_dim, chn_hid_dim, num_classes, p).to(device)\n",
        "inp = torch.randn(1, 3, 224, 224).to(device)\n",
        "out = net(inp)\n",
        "print(out.shape)\n",
        "del inp, out"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ9ct8xY8A4z"
      },
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "def get_accuracy(preds, y):\n",
        "    preds = preds.argmax(dim=1, keepdim=True)\n",
        "    correct = preds.squeeze(1).eq(y)\n",
        "    acc = correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
        "    return acc"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4Nn6-vJ71V8"
      },
      "source": [
        "def loop(net, loader, is_train):\n",
        "    net.train(is_train)\n",
        "    losses = []\n",
        "    accs = []\n",
        "    pbar = tqdm(loader, total=len(loader))\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            preds = net(x)\n",
        "            loss = loss_fn(preds, y)\n",
        "            acc = get_accuracy(preds, y)\n",
        "            losses.append(loss.item())\n",
        "            accs.append(acc.item())\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        pbar.set_description(f'epoch={epoch}, train={int(is_train)}')\n",
        "        pbar.set_postfix(loss=f'{np.mean(losses):.4f}', acc=f'{np.mean(accs):.4f}')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn4vrWhY9AHB",
        "outputId": "c064a73f-31b8-4f22-a744-821ad0b4dd2f"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    loop(net, train_loader, True)\n",
        "    loop(net, val_loader, False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=0, train=1: 100%|██████████| 782/782 [01:19<00:00,  9.89it/s, acc=0.4245, loss=1.5849]\n",
            "epoch=0, train=0: 100%|██████████| 157/157 [00:14<00:00, 11.16it/s, acc=0.5237, loss=1.3279]\n",
            "epoch=1, train=1: 100%|██████████| 782/782 [01:18<00:00,  9.90it/s, acc=0.5642, loss=1.2171]\n",
            "epoch=1, train=0: 100%|██████████| 157/157 [00:14<00:00, 11.11it/s, acc=0.5903, loss=1.1324]\n",
            "epoch=2, train=1: 100%|██████████| 782/782 [01:19<00:00,  9.87it/s, acc=0.6265, loss=1.0543]\n",
            "epoch=2, train=0: 100%|██████████| 157/157 [00:14<00:00, 11.18it/s, acc=0.6266, loss=1.0482]\n",
            "epoch=3, train=1: 100%|██████████| 782/782 [01:19<00:00,  9.85it/s, acc=0.6669, loss=0.9388]\n",
            "epoch=3, train=0: 100%|██████████| 157/157 [00:14<00:00, 11.08it/s, acc=0.6485, loss=0.9915]\n",
            "epoch=4, train=1: 100%|██████████| 782/782 [01:19<00:00,  9.78it/s, acc=0.7047, loss=0.8340]\n",
            "epoch=4, train=0: 100%|██████████| 157/157 [00:14<00:00, 11.06it/s, acc=0.6559, loss=0.9702]\n",
            "epoch=5, train=1: 100%|██████████| 782/782 [01:19<00:00,  9.81it/s, acc=0.7392, loss=0.7358]\n",
            "epoch=5, train=0: 100%|██████████| 157/157 [00:14<00:00, 11.10it/s, acc=0.6804, loss=0.9267]\n",
            "epoch=6, train=1: 100%|██████████| 782/782 [01:20<00:00,  9.73it/s, acc=0.7789, loss=0.6247]\n",
            "epoch=6, train=0: 100%|██████████| 157/157 [00:14<00:00, 10.97it/s, acc=0.6771, loss=0.9391]\n",
            "epoch=7, train=1: 100%|██████████| 782/782 [01:20<00:00,  9.74it/s, acc=0.8224, loss=0.5027]\n",
            "epoch=7, train=0: 100%|██████████| 157/157 [00:14<00:00, 10.73it/s, acc=0.6786, loss=0.9964]\n",
            "epoch=8, train=1: 100%|██████████| 782/782 [01:20<00:00,  9.68it/s, acc=0.8650, loss=0.3799]\n",
            "epoch=8, train=0: 100%|██████████| 157/157 [00:14<00:00, 10.95it/s, acc=0.6731, loss=1.0678]\n",
            "epoch=9, train=1: 100%|██████████| 782/782 [01:20<00:00,  9.71it/s, acc=0.9026, loss=0.2723]\n",
            "epoch=9, train=0: 100%|██████████| 157/157 [00:14<00:00, 10.87it/s, acc=0.6741, loss=1.1673]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}